---
title: "Practice-4"
author: "Harsh"
date: "13/06/2020"
output:
  html_document:
    df_print: paged
---

                                   ---Problem 1: SMS message filtering---

Step 1 & 2 – collecting, exploring and preparing the data

```{r}
#Importing Data using read.csv() function
sms_data <- read.csv("C:\\Users\\harsh\\Desktop\\Introduction to Machine learning and Data Mining\\Practice 4\\da5030.spammsgdataset.csv", header = TRUE, stringsAsFactors = FALSE)

#Exploring Data using head and str function. We can see that we have 2 features with 5574 number of total messages
head(sms_data)
str(sms_data)

```


```{r}

#sms_data$type is character vector, since it is a categorical variable we convert it to factors with 2 levels
sms_data$type <- as.factor(sms_data$type)

#verifying the datatype using str() function
str(sms_data)

#We count the total spam and ham messages using table function
table(sms_data$type)

```

Data preparation – processing text data for analysis

```{r}
#The tm text mining package is installed using install.packages() function
#install.packages("tm")
library(tm)

#We create a collection of text documents called  corpus. Since we have used vector data we use VectorSource() function
sms_corpus <- Corpus(VectorSource(sms_data$text))

#Using print we get a statement as A corpus with 5574 text documents
print(sms_corpus)

#To observe the content we use inspect() function
inspect(sms_corpus[1:2])

#We remove all the numbers and punctuations using tm_map() function. It is used to transform data.
corpus_clean <- tm_map(sms_corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, removePunctuation)
corpus_clean <- tm_map(corpus_clean, stripWhitespace)

#We verify using inspect whether all unwanted characters are removed
inspect(corpus_clean[1:2])

#Now we split sentences into individual words by using the process of tokenization. This is done by using DocumentTermMatrix()
sms_dtm <- DocumentTermMatrix(corpus_clean)

```

Data preparation – creating training and test datasets

```{r}

#We split the sms_data in 75:25 ratio and create train and test objects
sms_train_data <- sms_data[1:4181, ]
sms_test_data <- sms_data[4182:5574, ]

#Similarly we split tokenized data into train and test objects
sms_train_dtm <- sms_dtm[1:4181, ]
sms_test_dtm <- sms_dtm[4182:5574, ]

#Similarly we split corpus data into train and test objects
sms_train_corpus <- corpus_clean[1:4181]
sms_test_corpus <- corpus_clean[4182:5574]

#We compare the proportion of spam in the training and test data frames 
prop.table(table(sms_train_data$type))
prop.table(table(sms_test_data$type))

```

Visualizing text data – word clouds

```{r}
#Using the wordcloud package we visually depict the frequency at which words appear in text data.
#install.packages("wordcloud")
library(wordcloud)
library(stringr)

#A wordcloud is created using the train corpus data, we set the minimum word frequency as 40.
wordcloud(sms_train_corpus, min.freq = 40, random.order = FALSE)

#Now to visualize spam and ham of train data seperately we create a subset of them individually
spam <- subset(sms_train_data, type == "spam")
ham <- subset(sms_test_data, type == "ham")

#Since an error is generated because of a unknown graph element we replace that using str_replace function from the stringr library. 
#Solution provided by Annie Bryant
spam$text <- str_replace_all(spam$text,"[^[:graph:]]", " ")
ham$text <- str_replace_all(ham$text,"[^[:graph:]]", " ") 

#Visualization of spam and ham individually and we set the maximum words as 40 most common words
wordcloud(spam$text, max.words = 40, scale = c(3,0.5))
wordcloud(ham$text, max.words = 40, scale = c(3,0.5))

#We can observe that the most frequently used words in spam are call, free, stop, prize.

```

Data preparation – creating indicator features for frequent words

```{r}

library(tm)

#We find the word which have a frequency of 5 or more using findFreqTerms() function from tm library and observe it using head()
sms_dict <- findFreqTerms(sms_train_dtm, 5)
head(sms_dict)

#We create a sparse matrix of both train and test corpus data which have frequent words
sms_train <- DocumentTermMatrix(sms_train_corpus, list(dictionary = sms_dict))
sms_test <- DocumentTermMatrix(sms_test_corpus, list(dictionary = sms_dict))

#convert_counts functions is used to convert sparse matrix element numbers to a factor with Yes and No as 2 levels
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
return(x)
}

#Using apply() function we convert the sparse matrix elements by calling the convert_counts() function
sms_train <- apply(sms_train, MARGIN = 2, convert_counts)
sms_test <- apply(sms_test, MARGIN = 2, convert_counts)

```

Step 3 – training a model on the data

```{r}

library(e1071)
library(gmodels)

#First we build our model using naiveBayes() function from the e1071 library. We use the training data to train our model
sms_classifier <- naiveBayes(sms_train, sms_train_data$type)

```

Step 4 – evaluating model performance

```{r}

library(e1071)
library(gmodels)

#Here for prediction we have used testing sms data along with the predict() function to evaluate the performance of the model
sms_test_pred <- predict(sms_classifier, sms_test)

#To calculate the accuracy of the model we generate a crosstable. We can observe that 6 of the ham messages were predicted as spam and 28 spam messages were considered as ham. Considering the size of the data the error is pretty less.
CrossTable(sms_test_pred, sms_test_data$type, prop.chisq = FALSE, prop.t = FALSE, dnn = c('predicted', 'actual'))
```


Step 5 – improving model performance

```{r}

#We try to improve the performance of the model by using laplace = 1 in the naiveBayes() function. It helps in removing the words that appeared in zero spam or ham messages.
sms_classifier2 <- naiveBayes(sms_train, sms_train_data$type, laplace = 1)

#We test the new improved model
sms_test_pred2 <- predict(sms_classifier2, sms_test)

#We use crosstable to observe the improved performance of the model. We can observe that number of ham messages predicted as spam have reduced and spam as ham have increased.
CrossTable(sms_test_pred2, sms_test_data$type, prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE, dnn = c('predicted', 'actual'))

```

                        ---Problem 2: Classification of the built-in iris data using Naive Bayes---


```{r}

#We test the naiveBayes function using a different library called klaR package
#install.packages("klaR")
library(klaR)

#Loading the built-in dataset iris. We observe that the data consists of 5 features namely Sepal.Length, Sepal.Width, Petal.Length, Petal.Width and Species.
data(iris)

#Calculating the total number of rows present in the iris data using nrow() function
nrow(iris)

#Summary function helps in providing a detailed statistics of the data. It shows the mean,median,min,max and quartiles of the data ,also if there are any missing values they are printed in the summary itself. 
summary(iris)

#Head is used to show the top 6 rows of the data. This helps in exploring the data.
head(iris)

#With the help of which() function and a logic which basically means that every fifth row is stored in the testidx object this sums up as 20% of the whole data.
testidx <- which(1:length(iris[, 1]) %% 5 == 0)


#Separate into training and testing datasets
#Training data makes use of 80% of the data. This is done by using inverse of the testidx.
iristrain <- iris[-testidx,]

#In testing data we use testidx which is 20% of the data.
iristest <- iris[testidx,]

#Apply Naive Bayes
#Using the NaiveBayes() function from the klaR library. We specify the target variable i.e species and all other independent variables for classification as Species~.
nbmodel <- NaiveBayes(Species~., data=iristrain)

#Check the accuracy
#Prediction of the model is done using predict() function and we use the testing data without the last column
prediction <- predict(nbmodel, iristest[,-5])

#To calculate the accuracy we create a table to observe actual and predicted values
table(prediction$class, iristest[,5])

#We can see that only 2 virginica flowers were predicted as versicolor. We get the accuracy as 93.33%
acc <- ((10+10+8)/(10+10+10))*100
sprintf("The accuracy of the model is %s",acc)

```




