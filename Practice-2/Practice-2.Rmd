---
title: "Practice-2"
author: "Harsh"
date: "17/05/2020"
output:
  pdf_document: default
  html_document: default
---

Question 1 : The built-in dataset USArrests contains statistics about violent crime rates in the US States. Determine which states are outliers in terms of murders. Outliers, for the sake of this question, are defined as values that are more than 1.5 standard deviations from the mean.

```{r}

head(USArrests)

library(data.table)

usarrest_data <- USArrests

states <- data.table("States" = state.name)
usarrest_data <- cbind(states,usarrest_data)

mean_murder <- mean(usarrest_data$Murder)
sd_murder <- sd(usarrest_data$Murder)

z_score <- abs((mean_murder-usarrest_data$Murder)/sd_murder) 
z <- z_score > 1.5

outliers_states <- usarrest_data[z,1] 
outliers_states


# In this problem, first we import the data to usarrest_data variable. Since we don't have the state names in the data we import names from state.name dataset. Later we find the mean and std deviation to calculate z-score so that we can get the outlier states. Finally with the help of z-score we list the states that are >1.5 sd from mean.

```

Question 2 : For the same dataset as in (1), is there a correlation between urban population and murder, i.e., as one goes up, does the other statistic as well? Comment on the strength of the correlation. Calculate the Pearson coefficient of correlation in R.

```{r}

cor.test(usarrest_data$UrbanPop, usarrest_data$Murder)

library(ggpubr)
ggscatter(usarrest_data, x = "UrbanPop" , y = "Murder" , add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson", xlab = "Urban Population", ylab = "Murder")

# As we can see that the correlation between Urban population and Murder is very low (0.06). Because of this low value, we can observe in the plot that line is slightly positive. So we can conclude that as Urban population increases murder rate also increases but very slowly.

```

Question 3 : Based on the data on the growth of mobile phone use in Brazil (you'll need to copy the data and create a CSV that you can load into R or use the gsheet2tbl() function from the gsheet package), forecast phone use for the next time period using a 2-year weighted moving average (with weights of 5 for the most recent year, and 2 for other), exponential smoothing (alpha of 0.4), and linear regression trendline.

```{r}
# install.packages("gsheet")
library(gsheet)

mobile_data <- data.frame(gsheet2tbl("https://docs.google.com/spreadsheets/d/1tOnM9XceK4Ak8tzWQ2vDelWlJexzJiS3LbT6MN6_rW0/edit#gid=0"))

mobile_data <- mobile_data[-12,]


###############

# 2-year weighted average

n <- nrow(mobile_data)

last2 <- mobile_data[c(n,n-1), 2]
weight <- c(5,2)

sw <- weight*last2

weighted_average <- sum(sw)/sum(weight)


###############

# Exponential Smoothing with alpha = 0.4

mobile_data_1 <- mobile_data

alpha <- 0.4

mobile_data_1$Ft <- 0
mobile_data_1$E <- 0
mobile_data_1$sqrdError <- 0

mobile_data_1$Ft[1] <- mobile_data_1[1,2]

# F(t) = F(t-1) + a * E(t-1)

for (i in 2:nrow(mobile_data_1)) {
  mobile_data_1$Ft[i] <- mobile_data_1$Ft[i-1] + alpha * mobile_data_1$E[i-1]
  mobile_data_1$E[i] <- mobile_data_1$Subscribers[i] - mobile_data_1$Ft[i]
  mobile_data_1$sqrdError[i] <- mobile_data_1$E[i] ^ 2
}

forecast_exponential_smoothing <- mobile_data_1$Ft[n] + alpha * mobile_data_1$E[n]


###############

# Linear Regression 

mobile_data_2 <- mobile_data

model <- lm(mobile_data_2$Subscribers ~ mobile_data_2$Year)

summary(model)

print(model)

forecast_linear_regression <- -15710760 + 18276748 * 12 

###############


sprintf("2-year Moving Average : %s",weighted_average)
sprintf("Forecast with Exponential Smoothing : %s",forecast_exponential_smoothing)
sprintf("Forecast with linear regression : %s",forecast_linear_regression)


# In this problem we tested 3 types of forecasting methods on the same mobile data. I have duplicated the data for each model so as to avoid overwritting during the calculations. I have removed the last row from the mobile data because it was difficult to forecast using weigthed average method since it requires latest years.

```

Question 4 : Calculate the squared error for each model, i.e., use the model to calculate a forecast for each given time period and then the squared error. Finally, calculate the average (mean) squared error for each model. Which model has the smallest mean squared error (MSE)?

```{r}

mobile_data_3 <- mobile_data


###############

# MSE Calculation for Linear Regression method

mobile_data_3$F <- 0
mobile_data_3$absError <- 0
mobile_data_3$sqrdError <- 0

for (i in 1:nrow(mobile_data_3)) {
  mobile_data_3$F[i] <- -15710760 + 18276748 * mobile_data_3$Year[i]
  mobile_data_3$absError[i] <- abs(mobile_data_3$Subscribers[i] - mobile_data_3$F[i])
  mobile_data_3$sqrdError[i] <- mobile_data_3$absError[i] ^ 2
}

###############

# MSE Calculation for Weighted Average method

mobile_data_4 <- mobile_data

mobile_data_4$Forecast <- 0
mobile_data_4$Error <- 0
mobile_data_4$sqrdError <- 0

mobile_data_4$Forecast[1] <- mobile_data_4$Subscribers[1]
mobile_data_4$Forecast[2] <- mobile_data_4$Subscribers[2]



for (i in 3:nrow(mobile_data_4)) {
  last2year <- mobile_data_4$Subscribers[c(i-1,i-2)]
  weight <- c(5,2)
  sw1 <- weight*last2year
  mobile_data_4$Forecast[i] <- sum(sw1)/sum(weight)
  mobile_data_4$Error[i] <- abs(mobile_data_4$Subscribers[i]-mobile_data_4$Forecast[i])
  mobile_data_4$sqrdError[i] <- mobile_data_4$Error[i] ^ 2
}

###############

# Calculation of MSE for all 3 models
MSE_lm <- mean(mobile_data_3$sqrdError)

MSE_es <- mean(mobile_data_1$sqrdError)

MSE_wa <- mean(mobile_data_4$sqrdError)

sprintf("Mean Squared Error for Linear Regression : %s",MSE_lm)
sprintf("Mean Squared Error for Exponential Smoothing : %s",MSE_es)
sprintf("Mean Squared Error for 2-year Weighted Average : %s",MSE_wa)


# Table to observe the minimum MSE
model <- c("2-year Weighted Average", "Exponential Smoothing", "Linear Regression")
MSE <- c(MSE_wa,MSE_es,MSE_lm)
min_MSE <- data.frame(model,MSE)

min_MSE[order(MSE),]


# In this problem we calculated MSE for all 3 forecasts. Since we calculated the errors for exponential smoothing in previous question we just squared the values there itself and took the mean in this block. Apart from that, we have calculated the errors for weighted average forecast by using the same weights used before i.e (2,5). In the end we can observe the minimum value of MSE is for Linear regression which is shown in the table below. 

```

Question 5 : Calculate a weighted average forecast by averaging out the three forecasts calculated in (3) with the following weights: 4 for trend line, 2 for exponential smoothing, 1 for weighted moving average. Remember to divide by the sum of the weights in a weighted average.

```{r}

#Calculation of weighted average forecast of the above 3 forecasts 
values <- c(forecast_linear_regression,forecast_exponential_smoothing,weighted_average)

weights <- c(4,2,1)

wv <- values*weights

weighted_average_forecast <- sum(wv)/sum(weights)
weighted_average_forecast


# Here we created a new variable called values to store the output of the 3 forecasts which we calculated above. Later we use the new weights and get the weighted_average_forecast by using the same formula which we used before.

```


